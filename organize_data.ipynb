{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "25d94dd4-8a42-425d-a93c-47d901c64c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8d49241c-0d29-4445-bf5a-2cc0200370cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['Children', 'Biography', 'Comics', 'Fantasy Paranormal', 'Mystery Thriller Crime', 'Poetry', 'Young Adult', 'Romance']\n",
    "# categories = ['Children', 'Comics', 'Mystery Thriller Crime', 'Poetry', 'Young Adult', 'Romance']"
   ]
  },
  {
   "cell_type": "raw",
   "id": "790fe40a-af03-4328-bcfb-d0496f4b6f5d",
   "metadata": {},
   "source": [
    "\"\"\" What we want to do:\n",
    "1. merge the books subset\n",
    "2. handle individula interactions with user and books \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3ea5d9c4-96fc-43c7-942a-72bac7fbcb5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Children, 4995, 4997, 4995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cv/r6drvdzs40v0w7d6c9p4mbp80000gn/T/ipykernel_58580/500725024.py:18: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  total_df = pd.concat([total_df, merged_df])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Biography, 4997, 4998, 4997\n",
      "Comics, 4999, 4999, 4999\n",
      "Fantasy Paranormal, 4993, 4997, 4993\n",
      "Mystery Thriller Crime, 4996, 5000, 4996\n",
      "Poetry, 4995, 4994, 4995\n",
      "Young Adult, 4992, 5000, 4992\n",
      "Romance, 4996, 4999, 4996\n"
     ]
    }
   ],
   "source": [
    "total_df = pd.DataFrame(columns = ['user_id', 'book_id', 'rating', 'review_text', 'n_votes'] )\n",
    "# categories = ['Children']\n",
    "for category in categories:\n",
    "    interactions_df = pd.read_csv(f\"/Volumes/Drive/allenlu/Google Drive/My Drive/258/sampled/Goodreads_{category}_Interactions_sampled.csv\")\n",
    "    reviews_df = pd.read_csv(f\"/Volumes/Drive/allenlu/Google Drive/My Drive/258/sampled/Goodreads_{category}_Reviews_sampled.csv\")\n",
    "    \n",
    "    reviews_df['n_votes'] = reviews_df['n_votes'] + 1\n",
    "    merged_df = pd.merge(\n",
    "        interactions_df,\n",
    "        reviews_df[['user_id', 'book_id', 'rating', 'review_text', 'n_votes']],\n",
    "        on=['user_id', 'book_id', 'rating'],\n",
    "        how='left'\n",
    "    )\n",
    "    merged_df['n_votes'] = merged_df['n_votes'].fillna(0)\n",
    "    merged_df['review_text'] = merged_df['review_text'].fillna('')\n",
    "    merged_df.drop('is_read', axis=1, inplace=True)\n",
    "    print(f\"{category}, {len(interactions_df['book_id'].unique())}, {len(reviews_df['book_id'].unique())}, {len(merged_df['book_id'].unique())}\")\n",
    "    total_df = pd.concat([total_df, merged_df])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "299eed70-5002-498b-ba7c-f112cbc092f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_active_users_and_books(df, min_user_reviews=10, min_book_reviews=5):\n",
    "\n",
    "    user_review_counts = df['user_id'].value_counts()\n",
    "    active_users = user_review_counts[user_review_counts >= min_user_reviews].index\n",
    "    user_filtered_df = df[df['user_id'].isin(active_users)]\n",
    "    \n",
    "    book_review_counts = user_filtered_df['book_id'].value_counts()\n",
    "    active_books = book_review_counts[book_review_counts >= min_book_reviews].index\n",
    "    final_filtered_df = user_filtered_df[user_filtered_df['book_id'].isin(active_books)]\n",
    "    \n",
    "    final_filtered_df = final_filtered_df.reset_index(drop=True)\n",
    "    \n",
    "    print(\"User Statistics:\")\n",
    "    print(f\"Original number of users: {df['user_id'].nunique()}\")\n",
    "    print(f\"Number of users after filtering: {final_filtered_df['user_id'].nunique()}\")\n",
    "    print(f\"Min user reviews: {final_filtered_df['user_id'].value_counts().min()}\")\n",
    "    print(f\"Max user reviews: {final_filtered_df['user_id'].value_counts().max()}\")\n",
    "    \n",
    "    print(\"\\nBook Statistics:\")\n",
    "    print(f\"Original number of books: {df['book_id'].nunique()}\")\n",
    "    print(f\"Number of books after filtering: {final_filtered_df['book_id'].nunique()}\")\n",
    "    print(f\"Min book reviews: {final_filtered_df['book_id'].value_counts().min()}\")\n",
    "    print(f\"Max book reviews: {final_filtered_df['book_id'].value_counts().max()}\")\n",
    "    \n",
    "    print(f\"\\nTotal number of reviews after filtering: {len(final_filtered_df)}\")\n",
    "    \n",
    "    return final_filtered_df\n",
    "\n",
    "def calculate_user_book_statistics(df):\n",
    "\n",
    "    user_stats = {}\n",
    "    book_stats = {}\n",
    "    \n",
    "    user_groups = df.groupby('user_id')['rating']\n",
    "    user_means = user_groups.mean()\n",
    "    user_vars = user_groups.var()\n",
    "\n",
    "    for user_id in user_means.index:\n",
    "        user_stats[user_id] = {\n",
    "            'mean': user_means[user_id],\n",
    "            'variance': user_vars[user_id] if not pd.isna(user_vars[user_id]) else 0\n",
    "        }\n",
    "    \n",
    "    book_groups = df.groupby('book_id')['rating']\n",
    "    book_means = book_groups.mean()\n",
    "    book_vars = book_groups.var()\n",
    "\n",
    "    for book_id in book_means.index:\n",
    "        book_stats[book_id] = {\n",
    "            'mean': book_means[book_id],\n",
    "            'variance': book_vars[book_id] if not pd.isna(book_vars[book_id]) else 0\n",
    "        }\n",
    "    \n",
    "    return user_stats, book_stats\n",
    "\n",
    "def save_stats(user_stats, book_stats):\n",
    "    user_stats_clean = {\n",
    "        str(user_id): {\n",
    "            'mean': float(stats['mean']),\n",
    "            'variance': float(stats['variance'])\n",
    "        }\n",
    "        for user_id, stats in user_stats.items()\n",
    "    }\n",
    "    \n",
    "    book_stats_clean = {\n",
    "        str(book_id): {\n",
    "            'mean': float(stats['mean']),\n",
    "            'variance': float(stats['variance'])\n",
    "        }\n",
    "        for book_id, stats in book_stats.items()\n",
    "    }\n",
    "    \n",
    "    # Save user statistics\n",
    "    with open('user_stats.json', 'w') as f:\n",
    "        json.dump(user_stats_clean, f, indent=4)\n",
    "    \n",
    "    # Save book statistics\n",
    "    with open('book_stats.json', 'w') as f:\n",
    "        json.dump(book_stats_clean, f, indent=4)\n",
    "\n",
    "def count_books_by_genre(df):\n",
    "    # Group by genre and count unique book_ids\n",
    "    genre_counts = df.groupby('genre')['book_id'].nunique()\n",
    "    \n",
    "    # Sort values in descending order (optional)\n",
    "    genre_counts = genre_counts.sort_values(ascending=False)\n",
    "    \n",
    "    # Print results\n",
    "    print(\"Number of unique books in each genre:\")\n",
    "    for genre, count in genre_counts.items():\n",
    "        print(f\"{genre}: {count} books\")\n",
    "        \n",
    "    return genre_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b45b6434-5ae0-4511-9e99-dd93507374a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Statistics:\n",
      "Original number of users: 615068\n",
      "Number of users after filtering: 195667\n",
      "Min user reviews: 5\n",
      "Max user reviews: 1215\n",
      "\n",
      "Book Statistics:\n",
      "Original number of books: 39514\n",
      "Number of books after filtering: 31220\n",
      "Min book reviews: 5\n",
      "Max book reviews: 95167\n",
      "\n",
      "Total number of reviews after filtering: 4993063\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#filter the dataset further since we don't want books that only have 1 rating or users who only rated one book\n",
    "filter_df = filter_active_users_and_books(total_df, 10, 5)\n",
    "print('-----------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e604e20d-57b2-4857-a9e2-59efbf006c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_statistics, book_statistics = calculate_user_book_statistics(filter_df)\n",
    "save_stats(user_statistics, book_statistics)\n",
    "filter_df.to_csv('dataset.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "36d5e218-b17b-454d-a10d-5ec331b9b55d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cv/r6drvdzs40v0w7d6c9p4mbp80000gn/T/ipykernel_58580/3857239204.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_books = pd.concat([df_books, df])\n"
     ]
    }
   ],
   "source": [
    "#merge subset data\n",
    "df_books = pd.DataFrame(columns= ['book_id', 'title', 'average_rating', 'rating_variance', 'publication_year', 'num_pages', 'ratings_count', 'text_reviews_count','Children', 'Biography', 'Comics', 'Fantasy Paranormal', 'Mystery Thriller Crime', 'Poetry', 'Young Adult', 'Romance'])\n",
    "for category in categories:\n",
    "    file_path = f\"/Volumes/Drive/allenlu/Google Drive/My Drive/258/sampled/Goodreads {category} subset.csv\"\n",
    "    columns = ['book_id', 'title', 'average_rating', 'publication_year', 'num_pages', 'ratings_count', 'text_reviews_count']\n",
    "    df = pd.read_csv(file_path)\n",
    "    df = df[columns]\n",
    "    df[category] = 1\n",
    "    df['rating_variance'] = 0\n",
    "    df_books = pd.concat([df_books, df])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1792ff5d-ab97-4d35-ad93-d39a14b55ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_book_ids = filter_df['book_id'].unique()\n",
    "\n",
    "filtered_books = df_books[df_books['book_id'].isin(review_book_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5450cde3-1322-4e72-81b5-503d88d7c47e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (31643, 16)\n",
      "Merged shape: (31220, 16)\n",
      "\n",
      "Number of genres per book:\n",
      "1.0    30798\n",
      "2.0      421\n",
      "3.0        1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "merged_books = filtered_books.groupby('book_id').agg({\n",
    "    'title': 'first',  # Take the first title since it should be the same\n",
    "    'publication_year': 'first',  # Take the first year\n",
    "    'num_pages': 'first',  # Take the first number of pages\n",
    "    'average_rating': 'first',\n",
    "    'rating_variance': 'first',\n",
    "    'ratings_count': 'first',  # Take the first ratings count\n",
    "    'text_reviews_count': 'first',  # Take the first text reviews count\n",
    "    'Children': 'max',  # Take max for genre columns (0 or 1)\n",
    "    'Biography': 'max',\n",
    "    'Comics': 'max',\n",
    "    'Fantasy Paranormal': 'max',\n",
    "    'Mystery Thriller Crime': 'max',\n",
    "    'Poetry': 'max',\n",
    "    'Young Adult': 'max',\n",
    "    'Romance': 'max'\n",
    "}).reset_index()\n",
    "\n",
    "# Verify if the merging worked correctly\n",
    "print(\"Original shape:\", filtered_books.shape)\n",
    "print(\"Merged shape:\", merged_books.shape)\n",
    "\n",
    "# To check if any book still has multiple genres (there should be)\n",
    "genre_columns = ['Children', 'Biography', 'Comics', 'Fantasy Paranormal', \n",
    "                'Mystery Thriller Crime', 'Poetry', 'Young Adult', 'Romance']\n",
    "genres_per_book = merged_books[genre_columns].sum(axis=1)\n",
    "print(\"\\nNumber of genres per book:\")\n",
    "print(genres_per_book.value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "09ff39eb-def5-4a9f-85d1-b0b8aa6bc184",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cv/r6drvdzs40v0w7d6c9p4mbp80000gn/T/ipykernel_58580/3887039245.py:1: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_books.fillna(0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>title</th>\n",
       "      <th>publication_year</th>\n",
       "      <th>num_pages</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>rating_variance</th>\n",
       "      <th>ratings_count</th>\n",
       "      <th>text_reviews_count</th>\n",
       "      <th>Children</th>\n",
       "      <th>Biography</th>\n",
       "      <th>Comics</th>\n",
       "      <th>Fantasy Paranormal</th>\n",
       "      <th>Mystery Thriller Crime</th>\n",
       "      <th>Poetry</th>\n",
       "      <th>Young Adult</th>\n",
       "      <th>Romance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Harry Potter and the Prisoner of Azkaban (Harr...</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>435.0</td>\n",
       "      <td>4.53</td>\n",
       "      <td>0</td>\n",
       "      <td>1876252</td>\n",
       "      <td>28561</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>214</td>\n",
       "      <td>Sideswipe: A Hoke Moseley Novel</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>4.04</td>\n",
       "      <td>0</td>\n",
       "      <td>600</td>\n",
       "      <td>57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>244</td>\n",
       "      <td>The Puffin Book Of Nonsense Verse</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>287.0</td>\n",
       "      <td>4.04</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>289</td>\n",
       "      <td>The Beloved: Reflections on the Path of the Heart</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>4.18</td>\n",
       "      <td>0</td>\n",
       "      <td>300</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>290</td>\n",
       "      <td>Jesus the Son of Man</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>3.99</td>\n",
       "      <td>0</td>\n",
       "      <td>1174</td>\n",
       "      <td>71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31215</th>\n",
       "      <td>36348325</td>\n",
       "      <td>Nowhere to Run</td>\n",
       "      <td>0.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>4.22</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31216</th>\n",
       "      <td>36359242</td>\n",
       "      <td>Bluecollar Bear (Black Oak Bears #1)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.23</td>\n",
       "      <td>0</td>\n",
       "      <td>149</td>\n",
       "      <td>44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31217</th>\n",
       "      <td>36359314</td>\n",
       "      <td>How to Heal a Life (The Haven, #2)</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.05</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31218</th>\n",
       "      <td>36396964</td>\n",
       "      <td>Everything We Left Behind</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>4.04</td>\n",
       "      <td>0</td>\n",
       "      <td>730</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31219</th>\n",
       "      <td>36431429</td>\n",
       "      <td>Ghosted</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.68</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31220 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        book_id                                              title  \\\n",
       "0             5  Harry Potter and the Prisoner of Azkaban (Harr...   \n",
       "1           214                    Sideswipe: A Hoke Moseley Novel   \n",
       "2           244                  The Puffin Book Of Nonsense Verse   \n",
       "3           289  The Beloved: Reflections on the Path of the Heart   \n",
       "4           290                               Jesus the Son of Man   \n",
       "...         ...                                                ...   \n",
       "31215  36348325                                     Nowhere to Run   \n",
       "31216  36359242               Bluecollar Bear (Black Oak Bears #1)   \n",
       "31217  36359314                 How to Heal a Life (The Haven, #2)   \n",
       "31218  36396964                          Everything We Left Behind   \n",
       "31219  36431429                                            Ghosted   \n",
       "\n",
       "       publication_year  num_pages  average_rating  rating_variance  \\\n",
       "0                2004.0      435.0            4.53                0   \n",
       "1                2005.0      215.0            4.04                0   \n",
       "2                1996.0      287.0            4.04                0   \n",
       "3                1998.0      102.0            4.18                0   \n",
       "4                1995.0      216.0            3.99                0   \n",
       "...                 ...        ...             ...              ...   \n",
       "31215               0.0      264.0            4.22                0   \n",
       "31216               0.0        0.0            4.23                0   \n",
       "31217            2017.0        0.0            4.05                0   \n",
       "31218            2017.0      350.0            4.04                0   \n",
       "31219               0.0       25.0            2.68                0   \n",
       "\n",
       "       ratings_count  text_reviews_count  Children  Biography  Comics  \\\n",
       "0            1876252               28561       1.0        0.0     0.0   \n",
       "1                600                  57       0.0        0.0     0.0   \n",
       "2                 63                   6       0.0        0.0     0.0   \n",
       "3                300                  16       0.0        0.0     0.0   \n",
       "4               1174                  71       0.0        0.0     0.0   \n",
       "...              ...                 ...       ...        ...     ...   \n",
       "31215             16                  10       0.0        0.0     0.0   \n",
       "31216            149                  44       0.0        0.0     0.0   \n",
       "31217             45                  16       0.0        0.0     0.0   \n",
       "31218            730                  37       0.0        0.0     0.0   \n",
       "31219             34                  10       0.0        0.0     0.0   \n",
       "\n",
       "       Fantasy Paranormal  Mystery Thriller Crime  Poetry  Young Adult  \\\n",
       "0                     0.0                     0.0     0.0          0.0   \n",
       "1                     0.0                     1.0     0.0          0.0   \n",
       "2                     0.0                     0.0     1.0          0.0   \n",
       "3                     0.0                     0.0     1.0          0.0   \n",
       "4                     0.0                     0.0     1.0          0.0   \n",
       "...                   ...                     ...     ...          ...   \n",
       "31215                 0.0                     1.0     0.0          0.0   \n",
       "31216                 0.0                     0.0     0.0          0.0   \n",
       "31217                 0.0                     0.0     0.0          0.0   \n",
       "31218                 0.0                     1.0     0.0          0.0   \n",
       "31219                 1.0                     0.0     0.0          0.0   \n",
       "\n",
       "       Romance  \n",
       "0          0.0  \n",
       "1          0.0  \n",
       "2          0.0  \n",
       "3          0.0  \n",
       "4          0.0  \n",
       "...        ...  \n",
       "31215      0.0  \n",
       "31216      1.0  \n",
       "31217      1.0  \n",
       "31218      0.0  \n",
       "31219      0.0  \n",
       "\n",
       "[31220 rows x 16 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_books.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1e353e37-ed5b-49c5-b409-7a84badd3685",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in merged_books.iterrows():\n",
    "    merged_books.at[idx,'rating_variance'] =  book_statistics[row['book_id']]['variance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "af5aadbc-5c3f-4efb-a09c-42b54a9d9416",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_books.to_csv('books_data.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5d0d78-ecd4-4b69-817c-b69b05cda856",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
